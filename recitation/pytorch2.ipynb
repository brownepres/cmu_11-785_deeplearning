{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of dataloaders and simple neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim, torch.functional as F, torchvision, torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = SimpleNN(28*28, 10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),             # converts to [0,1]\n",
    "    transforms.Normalize((0.5,), (0.5,))  # optional: mean/std normalization\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33.6496)\n"
     ]
    }
   ],
   "source": [
    "print(net.fc1.weight.grad.abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 100] loss: 1.502\n",
      "[Epoch 1, Batch 200] loss: 0.545\n",
      "[Epoch 1, Batch 300] loss: 0.450\n",
      "[Epoch 1, Batch 400] loss: 0.409\n",
      "[Epoch 1, Batch 500] loss: 0.384\n",
      "[Epoch 1, Batch 600] loss: 0.345\n",
      "[Epoch 1, Batch 700] loss: 0.328\n",
      "[Epoch 1, Batch 800] loss: 0.304\n",
      "[Epoch 1, Batch 900] loss: 0.293\n",
      "[Epoch 1, Batch 1000] loss: 0.280\n",
      "[Epoch 1, Batch 1100] loss: 0.262\n",
      "[Epoch 1, Batch 1200] loss: 0.223\n",
      "[Epoch 1, Batch 1300] loss: 0.233\n",
      "[Epoch 1, Batch 1400] loss: 0.225\n",
      "[Epoch 1, Batch 1500] loss: 0.227\n",
      "[Epoch 1, Batch 1600] loss: 0.243\n",
      "[Epoch 1, Batch 1700] loss: 0.212\n",
      "[Epoch 1, Batch 1800] loss: 0.206\n",
      "[Epoch 2, Batch 100] loss: 0.195\n",
      "[Epoch 2, Batch 200] loss: 0.175\n",
      "[Epoch 2, Batch 300] loss: 0.173\n",
      "[Epoch 2, Batch 400] loss: 0.179\n",
      "[Epoch 2, Batch 500] loss: 0.167\n",
      "[Epoch 2, Batch 600] loss: 0.171\n",
      "[Epoch 2, Batch 700] loss: 0.151\n",
      "[Epoch 2, Batch 800] loss: 0.159\n",
      "[Epoch 2, Batch 900] loss: 0.173\n",
      "[Epoch 2, Batch 1000] loss: 0.137\n",
      "[Epoch 2, Batch 1100] loss: 0.153\n",
      "[Epoch 2, Batch 1200] loss: 0.181\n",
      "[Epoch 2, Batch 1300] loss: 0.153\n",
      "[Epoch 2, Batch 1400] loss: 0.166\n",
      "[Epoch 2, Batch 1500] loss: 0.184\n",
      "[Epoch 2, Batch 1600] loss: 0.137\n",
      "[Epoch 2, Batch 1700] loss: 0.142\n",
      "[Epoch 2, Batch 1800] loss: 0.128\n",
      "[Epoch 3, Batch 100] loss: 0.151\n",
      "[Epoch 3, Batch 200] loss: 0.132\n",
      "[Epoch 3, Batch 300] loss: 0.132\n",
      "[Epoch 3, Batch 400] loss: 0.121\n",
      "[Epoch 3, Batch 500] loss: 0.128\n",
      "[Epoch 3, Batch 600] loss: 0.135\n",
      "[Epoch 3, Batch 700] loss: 0.138\n",
      "[Epoch 3, Batch 800] loss: 0.115\n",
      "[Epoch 3, Batch 900] loss: 0.120\n",
      "[Epoch 3, Batch 1000] loss: 0.132\n",
      "[Epoch 3, Batch 1100] loss: 0.131\n",
      "[Epoch 3, Batch 1200] loss: 0.132\n",
      "[Epoch 3, Batch 1300] loss: 0.114\n",
      "[Epoch 3, Batch 1400] loss: 0.114\n",
      "[Epoch 3, Batch 1500] loss: 0.123\n",
      "[Epoch 3, Batch 1600] loss: 0.125\n",
      "[Epoch 3, Batch 1700] loss: 0.124\n",
      "[Epoch 3, Batch 1800] loss: 0.121\n",
      "[Epoch 4, Batch 100] loss: 0.107\n",
      "[Epoch 4, Batch 200] loss: 0.106\n",
      "[Epoch 4, Batch 300] loss: 0.102\n",
      "[Epoch 4, Batch 400] loss: 0.102\n",
      "[Epoch 4, Batch 500] loss: 0.093\n",
      "[Epoch 4, Batch 600] loss: 0.099\n",
      "[Epoch 4, Batch 700] loss: 0.103\n",
      "[Epoch 4, Batch 800] loss: 0.110\n",
      "[Epoch 4, Batch 900] loss: 0.099\n",
      "[Epoch 4, Batch 1000] loss: 0.100\n",
      "[Epoch 4, Batch 1100] loss: 0.089\n",
      "[Epoch 4, Batch 1200] loss: 0.113\n",
      "[Epoch 4, Batch 1300] loss: 0.094\n",
      "[Epoch 4, Batch 1400] loss: 0.089\n",
      "[Epoch 4, Batch 1500] loss: 0.087\n",
      "[Epoch 4, Batch 1600] loss: 0.089\n",
      "[Epoch 4, Batch 1700] loss: 0.111\n",
      "[Epoch 4, Batch 1800] loss: 0.107\n",
      "[Epoch 5, Batch 100] loss: 0.075\n",
      "[Epoch 5, Batch 200] loss: 0.078\n",
      "[Epoch 5, Batch 300] loss: 0.076\n",
      "[Epoch 5, Batch 400] loss: 0.079\n",
      "[Epoch 5, Batch 500] loss: 0.080\n",
      "[Epoch 5, Batch 600] loss: 0.088\n",
      "[Epoch 5, Batch 700] loss: 0.088\n",
      "[Epoch 5, Batch 800] loss: 0.092\n",
      "[Epoch 5, Batch 900] loss: 0.085\n",
      "[Epoch 5, Batch 1000] loss: 0.075\n",
      "[Epoch 5, Batch 1100] loss: 0.094\n",
      "[Epoch 5, Batch 1200] loss: 0.091\n",
      "[Epoch 5, Batch 1300] loss: 0.093\n",
      "[Epoch 5, Batch 1400] loss: 0.083\n",
      "[Epoch 5, Batch 1500] loss: 0.090\n",
      "[Epoch 5, Batch 1600] loss: 0.085\n",
      "[Epoch 5, Batch 1700] loss: 0.089\n",
      "[Epoch 5, Batch 1800] loss: 0.084\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "#training the network\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss=criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i%100 == 99:\n",
    "            print(f'[Epoch {epoch +1}, Batch {i+1}] loss: {running_loss/100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images:96.97%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy of the network on the 10000 test images:{100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.3097281455993652\n",
      "Loss after one step: 2.3097281455993652\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "outputs = net(images)\n",
    "loss = criterion(outputs, labels)\n",
    "print(\"Initial loss:\", loss.item())\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "outputs2 = net(images)\n",
    "loss2 = criterion(outputs2, labels)\n",
    "print(\"Loss after one step:\", loss2.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
